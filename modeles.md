
---
# Journée d'étude sur les "modèles de langage"
---
![en][en] [English](en/modeles.md)


## Présentation

Pour reprendre la [définition de Wikipedia](https://fr.wikipedia.org/wiki/Mod%C3%A8le_de_langage) : "En traitement automatique des langues, un modèle de langage est un modèle statistique qui modélise la distribution de séquences de mots, et plus généralement de séquences de symboles discrets (lettres, phonèmes, mots), dans une langue naturelle. Un modèle de langage peut par exemple prédire le mot suivant une séquence de mots. BERT et GPT-3 sont des modèles de langage".

Ces modèles, aujourd'hui omniprésent en traitement des langues, posent de nombreux problèmes : ils incluent de nombreux biais (biais de représentation liés au  genre, à l'âge ou à l'origine par exemple), ils nécessitent de grandes masses de données et ne sont donc disponibles qaue pour quelques langues. Enfin, ils sont très lourds à entraîner et ont donc un coût environnemental très important.  


Les questions liées aux modèles de langage ont été abordées lors de la journée du groupe "Ethique et Intelligence Artificielle" organisée en ligne le mercredi 1er juillet 2021. Le programme était le suivant :

* Benoît Sagot (INRIA) : Les modèles de langue neuronaux : biais de représentativité et de représentation  (la présentation sera mise en ligne dès sa réception)
* Karine Gentelet (UQO) : [Le numérique (et l'IA): un outil pertinent dans les stratégies politique/identitaire des Peuples autochtones du Canada](gentelet-modeles.pdf)
* Daniel Andler (IJN, IUF) : [Qui parle ?](andler-gpt3.pdf)

La réunion a eu lieu en ligne, sur Zoom. 

Notons, sur les mêmes questions, la [réflexion](https://hai.stanford.edu/news/reflections-foundation-models) menée au [Human Centered Artificial Intelligence Centre](https://hai.stanford.edu/) de Stanford, qui a produit un [rapport](https://arxiv.org/abs/2108.07258) et a organisé un [workshop](https://crfm.stanford.edu/workshop.html) dédié à ces questions. Le rapport contient une bonne synthèse des questions soulevées. 

Voir aussi, à titre d'introduction, l'artticle de Thierry Poibeau paru dans TheConversation : [Quand l’IA prend la parole : des prouesses aux dangers
](https://theconversation.com/quand-lia-prend-la-parole-des-prouesses-aux-dangers-153495)

